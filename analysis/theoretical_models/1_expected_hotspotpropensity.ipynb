{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute theoretical expected hotspot propensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea: compute expected number of hotspots in a region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "\n",
    "We model each trinucleotide context as an indepedendent region with constant mutation rate.\n",
    "\n",
    "Given a signature's trinucleotide profile, and a trinucleotide content and a mutation rate in a region of interest, we can compute the hotspot rate for each of the 32 trinucleotide contexts in the region.\n",
    "\n",
    "### Set-up\n",
    "\n",
    "Consider a stack of $N$ copies of the same DNA region of length $L$ where all positions in the region have the same reference triplet and mutation rate.\n",
    "\n",
    "Each position has identical mutability profile and each position can mutate in three different ways, non-necessarily with same mutation rate. \n",
    "\n",
    "The three posible substitutions are referred to as either $\\{A, B, C\\}$.\n",
    "\n",
    "#### Per position mutation probability\n",
    "\n",
    "So we will assume that each of the 3 specific mutation types $\\{A, B, C\\}$ has its own probability $p_A, p_B, p_C$.\n",
    "\n",
    "#### Per position hotspot probability\n",
    "\n",
    "A hotspot is called if the same mutation is found at the same position in at least two samples.\n",
    "\n",
    "We can think of a position as a stack of $N$ letters picked from the dictionary $\\Omega = \\{R,A,B,C\\}$. \"R\" means reference, it represents the event that there is not mutation at this position for that sample. Each position at each sample undergoes mutation with the same probability $p$ independently from other positions and samples. Thus for each level of the stack $R$ has probability $1-p$ and each $\\{A,B,C\\}$ have probabilities $p_A$, $p_B$, $p_C$, respectively, satisfying\n",
    "\n",
    "$$p_A + p_B + p_C = p.$$ \n",
    "\n",
    "Given a position, what are the chances that the stack has at least two identical letters of the set $\\{A, B, C\\}$? Such an event will be a \"hotspot\".\n",
    "\n",
    "$$\n",
    "P = 1 \n",
    "- \\textrm{prob that stack has all R's} \\\\ \n",
    "- \\textrm{prob that stack has exactly one A, B or C and rest R's} \\\\ \n",
    "- \\textrm{prob that stack has two of non-repeated A, B or C and rest R's} \\\\\n",
    "- \\textrm{prob that stack has three of non-repeated A, B or C and rest R's}\n",
    "$$\n",
    "\n",
    "Or equivalently:\n",
    "$$\n",
    "% P = 1 - (1 - p)^N \\\\\n",
    "% - N\\cdot p_A\\cdot (1-p)^{N-1}\n",
    "% - N\\cdot p_B\\cdot (1-p)^{N-1}\n",
    "% - N\\cdot p_C\\cdot (1-p)^{N-1} \\\\\n",
    "% - \\binom{N}{2}\\cdot 2! \\cdot p_A \\cdot p_B \\cdot (1-p)^{N-2} \n",
    "% - \\binom{N}{2}\\cdot 2! \\cdot p_A \\cdot p_C \\cdot (1-p)^{N-2}\n",
    "% - \\binom{N}{2}\\cdot 2! \\cdot p_B \\cdot p_C \\cdot (1-p)^{N-2} \\\\\n",
    "% - \\binom{N}{3}\\cdot 3! \\cdot p_A \\cdot p_B \\cdot p_C \\cdot (1-p)^{N-3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P = 1 \n",
    "- (1 - p)^N \\\\\n",
    "- N\\cdot (1-p)^{N-1} \\cdot \\left[p_A+p_B+p_C \\right] \\\\\n",
    "- N\\cdot (N-1) \\cdot (1-p)^{N-2} \\cdot \\left[ p_A \\cdot p_B + p_A \\cdot p_C + p_B \\cdot p_C\\right] \\\\\n",
    "- N\\cdot (N-1) \\cdot (N-2) \\cdot (1-p)^{N-3} \\cdot p_A \\cdot p_B \\cdot p_C\n",
    "$$\n",
    "\n",
    "#### Hotspot propensity estimates\n",
    "\n",
    "The number of hotspots follows a binomial distribution $\\textrm{Binom}(L, P)$, i.e.\n",
    "\n",
    "$$\\textrm{Prob}(n) = \\binom{L}{n} P^n (1 - P)^{L-n}$$\n",
    "\n",
    "and the expected number of hotspots (expected hotspot propensity) is simply:\n",
    "\n",
    "$$\n",
    "e = LP\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import triplets, mut_key_gen, mut_key_gen_cosmic, sum_dict, sbs_normalize, sbs_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load COSMIC Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb = dict(zip('ACGT','TGCA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosmic_df = pd.read_csv('./COSMIC_v3.2_SBS_GRCh38.txt', sep='\\t', index_col='Type')\n",
    "canonical_context_sorting = list(mut_key_gen_cosmic())\n",
    "cosmic_df = cosmic_df.loc[canonical_context_sorting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SBS1</th>\n",
       "      <th>SBS2</th>\n",
       "      <th>SBS3</th>\n",
       "      <th>SBS4</th>\n",
       "      <th>SBS5</th>\n",
       "      <th>SBS6</th>\n",
       "      <th>SBS7a</th>\n",
       "      <th>SBS7b</th>\n",
       "      <th>SBS7c</th>\n",
       "      <th>SBS7d</th>\n",
       "      <th>...</th>\n",
       "      <th>SBS85</th>\n",
       "      <th>SBS86</th>\n",
       "      <th>SBS87</th>\n",
       "      <th>SBS88</th>\n",
       "      <th>SBS89</th>\n",
       "      <th>SBS90</th>\n",
       "      <th>SBS91</th>\n",
       "      <th>SBS92</th>\n",
       "      <th>SBS93</th>\n",
       "      <th>SBS94</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A[C&gt;A]A</th>\n",
       "      <td>0.000876</td>\n",
       "      <td>5.790059e-07</td>\n",
       "      <td>0.020920</td>\n",
       "      <td>0.042451</td>\n",
       "      <td>0.012052</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.008946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032297</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.015677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A[C&gt;A]C</th>\n",
       "      <td>0.002220</td>\n",
       "      <td>1.455045e-04</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017495</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.052013</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.024523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A[C&gt;A]G</th>\n",
       "      <td>0.000180</td>\n",
       "      <td>5.361861e-05</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A[C&gt;A]T</th>\n",
       "      <td>0.001265</td>\n",
       "      <td>9.759122e-05</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.029663</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.020818</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>0.011141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C[C&gt;A]A</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>2.053143e-04</td>\n",
       "      <td>0.022376</td>\n",
       "      <td>0.080269</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.014348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024492</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.079522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SBS1          SBS2      SBS3      SBS4      SBS5      SBS6  \\\n",
       "Type                                                                      \n",
       "A[C>A]A  0.000876  5.790059e-07  0.020920  0.042451  0.012052  0.000425   \n",
       "A[C>A]C  0.002220  1.455045e-04  0.016343  0.032990  0.009337  0.000516   \n",
       "A[C>A]G  0.000180  5.361861e-05  0.001808  0.016116  0.001908  0.000053   \n",
       "A[C>A]T  0.001265  9.759122e-05  0.012265  0.029663  0.006636  0.000180   \n",
       "C[C>A]A  0.000305  2.053143e-04  0.022376  0.080269  0.007379  0.001800   \n",
       "\n",
       "            SBS7a     SBS7b     SBS7c     SBS7d  ...     SBS85     SBS86  \\\n",
       "Type                                             ...                       \n",
       "A[C>A]A  0.000067  0.002344  0.004841  0.000040  ...  0.006108  0.002968   \n",
       "A[C>A]C  0.000177  0.000457  0.001135  0.000754  ...  0.000871  0.003735   \n",
       "A[C>A]G  0.000073  0.000192  0.000388  0.000257  ...  0.000316  0.000398   \n",
       "A[C>A]T  0.000249  0.000714  0.001964  0.004051  ...  0.002728  0.003639   \n",
       "C[C>A]A  0.000451  0.001134  0.000108  0.014348  ...  0.004236  0.006076   \n",
       "\n",
       "            SBS87     SBS88     SBS89     SBS90     SBS91     SBS92     SBS93  \\\n",
       "Type                                                                            \n",
       "A[C>A]A  0.008946  0.000000  0.032297  0.002222  0.002934  0.011396  0.011628   \n",
       "A[C>A]C  0.004490  0.000000  0.017495  0.000704  0.052013  0.009653  0.008011   \n",
       "A[C>A]G  0.006357  0.000000  0.009971  0.000144  0.000209  0.004851  0.001817   \n",
       "A[C>A]T  0.004941  0.001738  0.020818  0.001771  0.000130  0.007800  0.008457   \n",
       "C[C>A]A  0.008436  0.000000  0.024492  0.001183  0.008071  0.018450  0.006456   \n",
       "\n",
       "            SBS94  \n",
       "Type               \n",
       "A[C>A]A  0.015677  \n",
       "A[C>A]C  0.024523  \n",
       "A[C>A]G  0.001627  \n",
       "A[C>A]T  0.011141  \n",
       "C[C>A]A  0.079522  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunksize selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunksize = '1000kb'    # Replace with '500kb', '250kb', '100kb', '50kb', '25kb', '10kb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trinucleotide content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2196"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_bins_f = f'{main_dir}/genomic_bins/data/hg38_{chunksize}_bin.nodrivers.filtered.mappable_positions.autosomes.binids.txt'\n",
    "available_bins_df = pd.read_csv(available_bins_f, sep='\\t', header=0)\n",
    "available_bins = set(available_bins_df['BINID'].unique())\n",
    "len(available_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triplet_counts_per_bin_fn = f'{main_dir}/genomic_bins/data/hg38_{chunksize}_bin.nodrivers.filtered.mappable_positions.autosomes.trinuc_per_bin.json'\n",
    "with open(triplet_counts_per_bin_fn, 'rt') as f:\n",
    "    triplet_counts_per_bin = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load triplet abundance per chunk\n",
    "triplet_abundance_array_dict = {}\n",
    "for chunk, d in triplet_counts_per_bin.items():\n",
    "    if chunk in available_bins: \n",
    "        triplet_abundance_array_dict[chunk] = sbs_format([d[t] for t in triplets()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genome-wide triplet abundance\n",
    "triplet_abundance_array_genomewide = {}\n",
    "for t, v in triplet_counts_per_bin.items():\n",
    "    if t in available_bins: \n",
    "        triplet_abundance_array_genomewide = sum_dict(triplet_abundance_array_genomewide, v)\n",
    "triplet_abundance_array_genomewide = sbs_format([triplet_abundance_array_genomewide[t] for t in triplets()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized mutation rate per chunk\n",
    "\n",
    "For each signature and tumor type, each chunk is given a weight and all the weights add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_list = []\n",
    "for fn in glob.glob(f'{main_dir}/genomic_bins/data/mutations_per_bin/*_*.{chunksize}.nodrivers.normmuts.total_maxprob.mutations_per_bin.relat_pcount.json'):\n",
    "    cancer_type = os.path.basename(fn).split('SBS')[0][:-1]\n",
    "    signature = 'SBS' + os.path.basename(fn).split('SBS')[1].split('.')[0]\n",
    "    zip_list.append((cancer_type, signature))\n",
    "cancer_types, signatures = tuple(zip(*zip_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mutrate_dict = {}\n",
    "for cancer_type, signature in zip(cancer_types, signatures):\n",
    "    \n",
    "    mutrate_fn = f'{main_dir}/genomic_bins/data/mutations_per_bin/{cancer_type}' \\\n",
    "                 f'_{signature}.{chunksize}.nodrivers.normmuts.total_maxprob.mutations_per_bin.relat_pcount.json'\n",
    "    with open(mutrate_fn, 'rt') as f:\n",
    "        mutrate_dict[(cancer_type, signature)] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TripletRegion class\n",
    "\n",
    "This class implements the method to compute expected number of hotspots described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from decimal import *\n",
    "\n",
    "class TripletRegion:\n",
    "    \n",
    "    getcontext().prec = 100  # using instances of decimal.Decimal() we can do arithmetic at an arbitrarily precision level\n",
    "    \n",
    "    def __init__(self, N, L, pa, pb, pc):\n",
    "        \n",
    "        \"\"\"\n",
    "        N: number of sample\n",
    "        L: region length\n",
    "        pa, pb, pc: per-base probabilities of either of 3 possible mutation types\n",
    "        \"\"\"\n",
    "        \n",
    "        self.N = Decimal(N)\n",
    "        self.L = L\n",
    "        self.pa = Decimal(pa)\n",
    "        self.pb = Decimal(pb)\n",
    "        self.pc = Decimal(pc)\n",
    "        self.p_mutation = self.pa + self.pb + self.pc\n",
    "        self.q = 1 - self.p_mutation\n",
    "    \n",
    "    @property\n",
    "    def p_hotspot(self):\n",
    "        t0 = self.q ** self.N\n",
    "        t1 = Decimal(self.N) * self.q ** (self.N - 1) * (self.pa + self.pb + self.pc)\n",
    "        t2 = Decimal(self.N) * Decimal(self.N - 1) * self.q ** (self.N - 2) * (self.pa * self.pb + self.pa * self.pc + self.pb * self.pc)\n",
    "        t3 = Decimal(self.N) * Decimal(self.N - 1) * Decimal(self.N - 2) * self.q ** (self.N - 3) * self.pa * self.pb * self.pc\n",
    "        return float(Decimal(1) - (t0 + t1 + t2 + t3))\n",
    "    \n",
    "    @property\n",
    "    def expected_hotspots(self):\n",
    "        return self.p_hotspot * self.L\n",
    "    \n",
    "    @property\n",
    "    def binomial_distribution(self):\n",
    "        rv = binom(self.L, self.p_hotspot)\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected number of hotspots per region with variable mutation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expected_hotspots_per_chunk(ttype, signature, muts_per_sample, N):\n",
    "    \n",
    "    \"\"\"\n",
    "    ttype: cancer type\n",
    "    signature: COSMIC signature\n",
    "    muts_per_sample: # mutations per sample \n",
    "    N: # samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # get normalized signature profile\n",
    "    sig = cosmic_df[signature].values\n",
    "    norm_sig = sbs_normalize(sig, triplet_abundance_array_genomewide)\n",
    "    \n",
    "    # get relative mutation rates\n",
    "    relative_mutation_rate_dict = mutrate_dict[(ttype, signature)]\n",
    "    \n",
    "    # sanity check\n",
    "    assert(len(relative_mutation_rate_dict.keys()) == len(triplet_abundance_array_dict.keys()))\n",
    "    \n",
    "    # dictionary with hotspot rate functions for each chunk\n",
    "    res = {}\n",
    "    for chunk, abundance in triplet_abundance_array_dict.items():\n",
    "        \n",
    "        # total mutrate for the chunk\n",
    "        L = int(sum(triplet_abundance_array_genomewide) / 3)\n",
    "        chunk_mutrate = muts_per_sample * relative_mutation_rate_dict[chunk]\n",
    "        \n",
    "        # estimate relative mutation load for each triplet genome\n",
    "        triplet_region_weights = {t: {'length': triplet_counts_per_bin[chunk][t], 'weights': []} for t in triplets()}\n",
    "\n",
    "        for i, s in enumerate(mut_key_gen()):\n",
    "            # mut_key_gen() yields s ~ (reference triplet, alternate)\n",
    "            triplet_region_weights[s[0]]['weights'] += [norm_sig[i]]\n",
    "\n",
    "        # mutrate\n",
    "        # dict: triplet -> mutation burden that corresponds to the \"triplet\" region in the chunk per sample, \n",
    "        # given i) the relative mutation rate of the chunk and ii) the number of mutations per sample\n",
    "\n",
    "        load = {t: sum(v['weights']) * v['length'] for t, v in triplet_region_weights.items()}\n",
    "        total_load = sum([v for t, v in load.items()])\n",
    "        mutrate = {t: (v / total_load) * chunk_mutrate for t, v in load.items()}\n",
    "        \n",
    "        # probabilities of for each mutation type within each triplet region\n",
    "        probabilities = {}\n",
    "        for t, v in triplet_region_weights.items():\n",
    "            if v['length'] > 0: \n",
    "                perposition_mutrate = mutrate[t] / v['length']\n",
    "                total_rate = sum(v['weights'])\n",
    "                pa = (v['weights'][0] / total_rate) * perposition_mutrate\n",
    "                pb = (v['weights'][1] / total_rate) * perposition_mutrate\n",
    "                pc = (v['weights'][2] / total_rate) * perposition_mutrate\n",
    "                probabilities[t] = (pa, pb, pc)\n",
    "            else: \n",
    "                probabilities[t] = (0, 0, 0)\n",
    "       \n",
    "        res[chunk] = 0\n",
    "        region = {}\n",
    "        for t, v in triplet_region_weights.items():\n",
    "            region[t] = TripletRegion(N, v['length'], *probabilities[t])\n",
    "        for t, v in region.items():\n",
    "            res[chunk] += v.expected_hotspots\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100  # number of samples\n",
    "n_muts = 300 # number of mutations\n",
    "cancer_type = 'COADREAD'\n",
    "signature = 'SBS1'\n",
    "\n",
    "results_d = expected_hotspots_per_chunk(cancer_type, signature, n_muts, N)\n",
    "expected_hotspot_propensity_sig = sum(results_d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_f = f'{chunksize}_{cancer_type}_{signature}_{int(n_muts)}_{int(N)}.nodrivers.relat_pcount.json'\n",
    "with open(output_f, 'wt') as f:\n",
    "    json.dump(results_d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected number of hotspots assuming same mutation rate across the genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load trinucleotide content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunksize = '1000kb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2196"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_bins_f = f'{main_dir}/genomic_bins/data/hg38_{chunksize}_bin.nodrivers.filtered.mappable_positions.autosomes.binids.txt'\n",
    "available_bins_df = pd.read_csv(available_bins_f, sep='\\t', header=0)\n",
    "available_bins = set(available_bins_df['BINID'].unique())\n",
    "len(available_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triplet_counts_per_bin_fn = f'{main_dir}/genomic_bins/data/hg38_{chunksize}_bin.nodrivers.filtered.mappable_positions.autosomes.trinuc_per_bin.json'\n",
    "with open(triplet_counts_per_bin_fn, 'rt') as f:\n",
    "    triplet_counts_per_bin = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load triplet abundance per chunk\n",
    "triplet_abundance_array_dict = {}\n",
    "for chunk, d in triplet_counts_per_bin.items():\n",
    "    if chunk in available_bins: \n",
    "        triplet_abundance_array_dict[chunk] = sbs_format([d[t] for t in triplets()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genome-wide triplet abundance\n",
    "triplet_abundance_array_genomewide = {}\n",
    "for t, v in triplet_counts_per_bin.items():\n",
    "    if t in available_bins: \n",
    "        triplet_abundance_array_genomewide = sum_dict(triplet_abundance_array_genomewide, v)\n",
    "triplet_abundance_array_genomewide = sbs_format([triplet_abundance_array_genomewide[t] for t in triplets()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = int(sum(triplet_abundance_array_genomewide) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expected_hotspots_uniform_genome(signature, mutrate_per_megabase):\n",
    "    \n",
    "    \"\"\"Returns a function that produces a result for a given input number of samples\"\"\"\n",
    "        \n",
    "    # triplet abundance\n",
    "    \n",
    "    abundance = triplet_abundance_array_genomewide\n",
    "        \n",
    "    # read COSMIC signatures table\n",
    "    \n",
    "    cosmic_df = pd.read_csv('./COSMIC_v3.2_SBS_GRCh38.txt', sep='\\t', index_col='Type')\n",
    "    canonical_context_sorting = list(mut_key_gen_cosmic())\n",
    "    cosmic_df = cosmic_df.loc[canonical_context_sorting]\n",
    "    \n",
    "    # get normalized signature profile\n",
    "\n",
    "    sig = cosmic_df[signature].values\n",
    "    norm_sig = sig / np.array(abundance)\n",
    "    norm_sig /= sum(norm_sig)\n",
    "\n",
    "    # estimate relative mutation burden for each triplet genome\n",
    "\n",
    "    triplet_genome_weights = {\n",
    "        s[0]: {'length': abundance[i], 'weights': []} for i, s in enumerate(mut_key_gen())}\n",
    "\n",
    "    for i, s in enumerate(mut_key_gen()):\n",
    "        triplet_genome_weights[s[0]]['weights'] += [norm_sig[i]]\n",
    "        \n",
    "    # total genome length\n",
    "\n",
    "    L = sum([v['length'] for t, v in triplet_genome_weights.items()])\n",
    "    \n",
    "    # mutrates\n",
    "    \n",
    "    total_mutrate = mutrate_per_megabase * L / 1e6\n",
    "    load = {k: sum(v['weights']) * v['length'] for k, v in triplet_genome_weights.items()}\n",
    "    total_load = sum([v for k, v in load.items()])\n",
    "    mutrate = {k: (v / total_load) * total_mutrate for k, v in load.items()}\n",
    "    \n",
    "    # probabilities of mutation types within each triplet genome\n",
    "\n",
    "    probabilities = {}\n",
    "    for k, v in triplet_genome_weights.items():\n",
    "        perposition_mutrate = mutrate[k] / v['length']\n",
    "        total_rate = sum(v['weights'])\n",
    "        pa = (v['weights'][0] / total_rate) * perposition_mutrate\n",
    "        pb = (v['weights'][1] / total_rate) * perposition_mutrate\n",
    "        pc = (v['weights'][2] / total_rate) * perposition_mutrate\n",
    "        probabilities[k] = (pa, pb, pc)\n",
    "    \n",
    "    # function instance\n",
    "    \n",
    "    def func_expected(N):\n",
    "        \n",
    "        genome = {}\n",
    "        for triplet, v in triplet_genome_weights.items():\n",
    "            genome[triplet] = TripletRegion(N, v['length'], *probabilities[triplet])\n",
    "        \n",
    "        res = {}\n",
    "        for k, v in genome.items():\n",
    "            res[k] = {'length': triplet_genome_weights[k]['length'], \n",
    "                      'expected_hotspots': v.expected_hotspots, \n",
    "                      'p_hotspots': v.p_hotspot}\n",
    "        return res\n",
    "        \n",
    "    return func_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uniform model output based on mutations per sample\n",
    "selected_signatures = set(tuple(zip(*zip_list))[1])\n",
    "m_grid = [300, 600]\n",
    "N_grid = list(map(int, np.linspace(100, 1000, num=19)))\n",
    "\n",
    "results = []\n",
    "\n",
    "for m in m_grid:\n",
    "    mutation_rate_per_megabase = m / (L / 1e6)\n",
    "    for sig in selected_signatures:\n",
    "        func_expected = expected_hotspots_uniform_genome(sig, mutation_rate_per_megabase)\n",
    "        for n in N_grid:\n",
    "            res = func_expected(n)\n",
    "            total_expected_hotspots = sum([v['expected_hotspots'] for v in res.values()])\n",
    "            results.append((m, sig, n, total_expected_hotspots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('expected_hotspots_genomewide_disallowed.json', 'wt') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_signatures = set(tuple(zip(*zip_list))[1])\n",
    "m_grid = [0.1, 0.5, 1., 5., 10.]\n",
    "N_grid = list(map(int, np.linspace(100, 1000, num=19)))\n",
    "\n",
    "results = []\n",
    "\n",
    "for mutation_rate_per_megabase in m_grid:\n",
    "    for sig in selected_signatures:\n",
    "        func_expected = expected_hotspots_uniform_genome(sig, mutation_rate_per_megabase)\n",
    "        for n in N_grid:\n",
    "            res = func_expected(n)\n",
    "            total_expected_hotspots = sum([v['expected_hotspots'] for v in res.values()])\n",
    "            results.append((mutation_rate_per_megabase, sig, n, total_expected_hotspots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('expected_hotspots_genomewide_disallowed_mutspermb.json', 'wt') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hotspots_framework]",
   "language": "python",
   "name": "conda-env-hotspots_framework-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
