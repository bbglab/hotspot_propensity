{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute length and trinucleotide sequence of mappable bins \n",
    "\n",
    "For each set of bins of length between 1 Mbp and 10 Kbp, compute their length and their sequence composition (trinucleotide content). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from bgreference import hg38\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_comp(seq):\n",
    "    \"\"\"Compute reverse complementary of a sequence\"\"\"\n",
    "    comp_nucleotides = {\n",
    "        'A': 'T',\n",
    "        'C': 'G',\n",
    "        'G': 'C',\n",
    "        'T': 'A'\n",
    "    }\n",
    "    return ''.join(list(map(lambda x: comp_nucleotides[x], seq[::-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autosomes = [f'chr{i}' for i in range(1, 23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pyrimidine-based reference trinucleotides\n",
    "sorted_trinuc = []\n",
    "for n2 in ['C', 'T']:\n",
    "    for n1 in ['A', 'C', 'G', 'T']:\n",
    "        for n3 in ['A', 'C', 'G', 'T']:\n",
    "            sorted_trinuc.append(n1 + n2 + n3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute length \n",
    "\n",
    "Check that all bins expand the same length of the genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [1000000, 500000, 250000, 100000, 50000, 25000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 1000kb\n",
      "Length = 2012091302\n",
      "Computing 500kb\n",
      "Length = 2012091302\n",
      "Computing 250kb\n",
      "Length = 2012091302\n",
      "Computing 100kb\n",
      "Length = 2012091302\n",
      "Computing 50kb\n",
      "Length = 2012091302\n",
      "Computing 25kb\n",
      "Length = 2012091302\n",
      "Computing 10kb\n",
      "Length = 2012091302\n"
     ]
    }
   ],
   "source": [
    "for binsize in bins: \n",
    "    bin_name = f'{int(binsize/1000)}kb'\n",
    "    print(f'Computing {bin_name}')\n",
    "    \n",
    "    bins_file = f'{main_dir}/data/hg38_{bin_name}_bin.nodrivers.filtered.mappable_positions.autosomes.bed.gz'\n",
    "    length = 0\n",
    "    with gzip.open(bins_file, 'rt') as fd: \n",
    "        next(fd)     # skip header\n",
    "        for line in fd: \n",
    "            chrom, start, end, binid = line.strip().split('\\t')\n",
    "            if chrom in autosomes: \n",
    "                start = int(start) + 1    # undo BED format\n",
    "                end = int(end)\n",
    "                size = end - start + 1\n",
    "                length += len(hg38(chrom, start, size=size))\n",
    "    print(f'Length = {length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute trinucleotide composition \n",
    "\n",
    "Calculate trinucleotide content for each bin across bin sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [1000000, 500000, 250000, 100000, 50000, 25000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trinucleotide_counts_bin(bins_file): \n",
    "    \"\"\"Count trinucleotide composition across bins in a file containing bins\"\"\"\n",
    "    \n",
    "    trinucleotides_per_bin = defaultdict(dict)\n",
    "    \n",
    "    with gzip.open(bins_file, 'rt') as fd:\n",
    "        next(fd)    # skip header\n",
    "        for i, line in enumerate(tqdm(fd)):\n",
    "            chrom, start, end, binid = line.strip().split()\n",
    "            # Account for trinucleotide sequence (substract 1 position to start; add 1 position to end)\n",
    "            start = int(start)     # undo BED format --> start - 1 + 1\n",
    "            end = int(end) + 1\n",
    "            size = end - start + 1\n",
    "            nucleotide_sequence = hg38(chrom, start, size=size)\n",
    "            trinucleotides = Counter([nucleotide_sequence[i:i + 3] for i in range(len(nucleotide_sequence) - 2)])\n",
    "            trinucleotides_per_bin[binid] = Counter(trinucleotides_per_bin[binid]) + trinucleotides\n",
    "                \n",
    "    return trinucleotides_per_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 1000kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11678127it [16:05, 12099.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbins with sequence: 2196\n",
      "\tbins missing sequence: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1090it [00:00, 10898.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 500kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11680122it [17:29, 11129.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbins with sequence: 4392\n",
      "\tbins missing sequence: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [00:00, 2518.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 250kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11684130it [18:51, 10323.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbins with sequence: 8784\n",
      "\tbins missing sequence: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "913it [00:00, 9122.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 100kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11696068it [18:20, 10625.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbins with sequence: 21940\n",
      "\tbins missing sequence: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 50kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11716057it [18:32, 10528.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbins with sequence: 43785\n",
      "\tbins missing sequence: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 25kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11756066it [17:09, 11421.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbins with sequence: 87367\n",
      "\tbins missing sequence: 473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 10kb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11876173it [17:43, 11167.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbins with sequence: 217968\n",
      "\tbins missing sequence: 1632\n"
     ]
    }
   ],
   "source": [
    "for binsize in bins: \n",
    "\n",
    "    bin_name = f'{int(binsize/1000)}kb'\n",
    "    print(f'Computing {bin_name}')\n",
    "\n",
    "    bins_file = f'{main_dir}/data/hg38_{bin_name}_bin.nodrivers.filtered.mappable_positions.autosomes.bed.gz'\n",
    "    all_bins_f = f'{main_dir}/data/hg38_{bin_name}_bin.nodrivers.filtered.all_positions.autosomes.bed.gz'\n",
    "\n",
    "    output_f1 = f'{main_dir}/data/hg38_{bin_name}_bin.nodrivers.filtered.mappable_positions.autosomes.trinuc_per_bin.json'\n",
    "    output_f2 = f'{main_dir}/data/hg38_{bin_name}_bin.nodrivers.filtered.mappable_positions.autosomes.trinuc_merged_bins.json'\n",
    "\n",
    "    # Get trinucleotides per bin\n",
    "    trinucleotides_per_bin = trinucleotide_counts_bin(bins_file)\n",
    "    print(f'\\tbins with sequence: {len(trinucleotides_per_bin.keys())}')\n",
    "    \n",
    "    #Add missing bins\n",
    "    all_bins_df = pd.read_csv(all_bins_f, sep='\\t', header=0)\n",
    "    total_bins = all_bins_df['BINID'].unique()\n",
    "    missing_bins = set(total_bins).difference(set(trinucleotides_per_bin.keys()))\n",
    "    print(f'\\tbins missing sequence: {len(missing_bins)}')\n",
    "\n",
    "    for binid in missing_bins: \n",
    "        chrom, start_end = binid.split(':')\n",
    "        start, end = start_end.split('-')\n",
    "        start = int(start) if int(start) > 0 else 1\n",
    "        end = int(end) + 1\n",
    "        size = end - start + 1\n",
    "        nucleotide_sequence = hg38(chrom, start, size=size)\n",
    "        trinucleotides = Counter([nucleotide_sequence[i:i + 3] for i in range(len(nucleotide_sequence) - 2)])\n",
    "        trinucleotides_per_bin[binid] = trinucleotides\n",
    "    \n",
    "    # Collapse trinucleotide counts per bin\n",
    "    trinucleotides_per_bin_v2 = {}\n",
    "    # For each trinucleotide, save its counts across all bins in a list\n",
    "    counts_per_trinucleotide = defaultdict(list)\n",
    "    # Compute\n",
    "    for binid, counter in trinucleotides_per_bin.items():\n",
    "        trinucleotides_per_bin_v2[binid] = {}\n",
    "        for trinucleotide in sorted_trinuc:\n",
    "            counts = counter[trinucleotide] + counter[rev_comp(trinucleotide)]    # add up complementary trinucleotides\n",
    "            trinucleotides_per_bin_v2[binid][trinucleotide] = counts\n",
    "            counts_per_trinucleotide[trinucleotide] += [counts]\n",
    "\n",
    "    # Undo defaultdict counts_per_trinucleotide (not compatible with json)\n",
    "    counts_per_trinucleotide_v2 = {}\n",
    "    for k, v in counts_per_trinucleotide.items():\n",
    "        counts_per_trinucleotide_v2[k] = v\n",
    "\n",
    "    # Trinucleotide counts per bin (bins as keys)\n",
    "    with open(output_f1, 'w') as ofd:\n",
    "        json.dump(trinucleotides_per_bin_v2, ofd)\n",
    "\n",
    "    # Trinucleotide counts across bins (trinucleotide as keys)\n",
    "    with open(output_f2, 'w') as ofd:\n",
    "        json.dump(counts_per_trinucleotide_v2, ofd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hotspots_framework]",
   "language": "python",
   "name": "conda-env-hotspots_framework-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
